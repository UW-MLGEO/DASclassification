{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import das_package as dp\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Raw Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012014Z.h5 already stored locally\n",
      "South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012114Z.h5 already stored locally\n",
      "South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012214Z.h5 already stored locally\n",
      "South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012314Z.h5 already stored locally\n",
      "South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012414Z.h5 already stored locally\n",
      "['Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012014Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012114Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012214Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012314Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012414Z.h5']\n"
     ]
    }
   ],
   "source": [
    "interrogator = \"Optasense\"     #Optasense or Silixa\n",
    "ship_number = 1\n",
    "folder = f\"Data/Raw/Ship{ship_number}\"\n",
    "results_folder = f\"{folder}/results\" \n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "url = \"http://piweb.ooirsn.uw.edu/das/data/Optasense/SouthCable/TransmitFiber/South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-01T16_09_15-0700/South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012014Z.h5\"\n",
    "first_file_time = dp.find_time_url(url, interrogator)\n",
    "file_timing_length = 60\n",
    "minutes = 5\n",
    "n = int(minutes*60/file_timing_length)\n",
    "all_filenames = dp.dl_das_files(folder, url, first_file_time, file_timing_length, n)\n",
    "filenames = sorted([file for file in all_filenames if file != f\"{folder}\\\\results\"])\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concatenated data shape: (47500, 60000)\n",
      "The first value in \"RawDataTime\" is 1635902414834000 which is the timestamp of the first sample in microseconds.\n",
      "This equates to the date and time 2021-11-03 01:20:14.834000\n",
      "the time step is equal to =  5000.0 microsecond\n",
      "\n",
      "sampling rate in Hz =  200.0\n",
      "channel spacing in m =  2.0419047\n",
      "number of channels =  47500\n",
      "number of samples in each channel =  60000\n",
      "gauge length in m =  51.04762\n"
     ]
    }
   ],
   "source": [
    "if interrogator == 'Optasense':\n",
    "    rawData, dt, fs, dx, nx, ns, GL, sf, starting_time_timestamp = dp.optasense(filenames)\n",
    "\n",
    "elif interrogator == 'Silixa':\n",
    "    rawData, dt, fs, dx, nx, ns, GL, sf, starting_time_timestamp = dp.silixa(filenames)\n",
    "\n",
    "\n",
    "# Downsample factors and channel chunking size\n",
    "if fs == 1000:\n",
    "    factor_channels = 2\n",
    "    factor_time = 5\n",
    "    ch_chunk_size = 500\n",
    "elif fs == 500:\n",
    "    factor_channels = 2\n",
    "    factor_time = 2\n",
    "    ch_chunk_size = 700\n",
    "elif fs == 200:\n",
    "    factor_channels = 2\n",
    "    factor_time = 1\n",
    "    ch_chunk_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Raw Data to AI-Ready Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of itterations:  2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012014Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012114Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012214Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012314Z.h5', 'Data/Raw/Ship1\\\\South-C1-LR-95km-P1kHz-GL50m-SP2m-FS200Hz_2021-11-03T012414Z.h5']\n"
     ]
    }
   ],
   "source": [
    "distance = [20000, 25000]\n",
    "if dx<2:\n",
    "    chint = 1\n",
    "elif dx>=2:\n",
    "    chint = 1                        \n",
    "duration = [0, int(ns/fs)]            #in second1\n",
    "tint = 1                         #time interval (sample)\n",
    "\n",
    "\n",
    "#Converting selected distance from meter to channels\n",
    "channels = [int(distance[0]/dx), int(distance[1]/dx), chint]\n",
    "\n",
    "#Finding number of itterations\n",
    "itteration = (((channels[1] - channels[0]) / chint)//ch_chunk_size)\n",
    "print('Number of itterations: ', itteration)\n",
    "\n",
    "\n",
    "### Raw to strain rate ###\n",
    "#Determine the first chunck of data\n",
    "channels_chunk = [int(distance[0]/dx), min(int(distance[0]/dx) + ch_chunk_size*chint , int(distance[1]/dx)), chint]\n",
    "time_chunk = [int(duration[0]*fs), int(duration[1]*fs), tint]\n",
    "\n",
    "#Doing analysis for first chunk of data\n",
    "trace, dist, time, starting_time_utc = dp.chunk_load(rawData, channels_chunk, time_chunk, dt, fs, dx, sf, starting_time_timestamp)\n",
    "if interrogator == 'Optasense':\n",
    "    str_rate = dp.strain2strainrate(trace, dt, tint)\n",
    "elif interrogator == 'Silixa':\n",
    "    str_rate = trace\n",
    "\n",
    "#Doing analysis for remained chunks of data\n",
    "for i in tqdm(range(int(itteration))):\n",
    "\n",
    "    if (channels_chunk[1] + ch_chunk_size*chint)*dx >= distance[1]:\n",
    "        channels_chunk = [channels_chunk[1], int(distance[1]/dx), chint]\n",
    "    else:\n",
    "        channels_chunk = [channels_chunk[1], channels_chunk[1] + ch_chunk_size*chint, chint]\n",
    "\n",
    "    if channels_chunk[1] - channels_chunk[0] < 0.1*ch_chunk_size :\n",
    "        break\n",
    "\n",
    "    trace, dist_chunk, time, starting_time_utc = dp.chunk_load(rawData, channels_chunk, time_chunk, dt, fs, dx, sf, starting_time_timestamp)\n",
    "    dist = np.concatenate([dist, dist_chunk])\n",
    "    if interrogator == 'Optasense':\n",
    "        str_rate_chunk = dp.strain2strainrate(trace, dt, tint)\n",
    "    elif interrogator == 'Silixa':\n",
    "        str_rate_chunk = trace\n",
    "    str_rate = np.concatenate([str_rate, str_rate_chunk], axis=0)\n",
    "    del str_rate_chunk, dist_chunk\n",
    "\n",
    "np.save(f'{folder}/results/str_rate{ship_number}', str_rate)\n",
    "np.save(f'{folder}/results/time{ship_number}', time)\n",
    "np.save(f'{folder}/results/dist{ship_number}', dist)\n",
    "\n",
    "del trace, rawData\n",
    "\n",
    "if interrogator == 'Optasense':\n",
    "    files = glob.glob(os.path.join(folder, '*.h5'))\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "\n",
    "elif interrogator == 'Silixa':\n",
    "    files = glob.glob(os.path.join(folder, '*.tdms'))\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        os.remove(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLGeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
